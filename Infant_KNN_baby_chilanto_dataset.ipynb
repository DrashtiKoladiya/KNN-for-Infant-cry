{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ad3d96ef",
      "metadata": {
        "id": "ad3d96ef"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6d85800f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def mfcc_mine(sr,audio):\n",
        "    mfccs=librosa.feature.mfcc(y=audio,sr=sr,n_mfcc=13)\n",
        "    mfccs_array=np.array(mfccs.T)\n",
        "    mfccs_processed=np.mean(mfccs.T,axis=0)\n",
        "    return mfccs_processed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b673e287",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total files of deaf: 885\n",
            "total files of normal: 507\n",
            "total files of pain: 192\n",
            "total files of asphyxia: 340\n",
            "total files of hunger: 350\n"
          ]
        }
      ],
      "source": [
        "#---------------------------------#loading data----------------------------------\n",
        "path1=r\"C:\\Drashti\\Infant\\baby_chilanto_infantcry_dataset\\deaf\"\n",
        "print('total files of deaf:',len(os.listdir(path1)))\n",
        "path2=r\"C:\\Drashti\\Infant\\baby_chilanto_infantcry_dataset\\normal\"\n",
        "print('total files of normal:',len(os.listdir(path2)))\n",
        "path3=r\"C:\\Drashti\\Infant\\baby_chilanto_infantcry_dataset\\pain\"\n",
        "print('total files of pain:',len(os.listdir(path3)))\n",
        "path5=r\"C:\\Drashti\\Infant\\baby_chilanto_infantcry_dataset\\asphyxia\"\n",
        "print('total files of asphyxia:',len(os.listdir(path5)))\n",
        "path6=r\"C:\\Drashti\\Infant\\baby_chilanto_infantcry_dataset\\hunger\"\n",
        "print('total files of hunger:',len(os.listdir(path6)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d145466d",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dataset =[]\n",
        "train_labels=[]\n",
        "train_extracted1=[]\n",
        "train_extracted_del1=[]\n",
        "train_extracted_ddel1=[]\n",
        "# class deaf\n",
        "files = os.listdir(path1)\n",
        "for i in files:\n",
        "  string = path1 + '/'+i\n",
        "  data,sr = librosa.load(string)\n",
        "  train_dataset.append(data)\n",
        "  train_labels.append('pathology')  \n",
        "  feat,del_feat,ddel_feat=mfcc_mine(sr,data)  \n",
        "  train_extracted1.append(feat)\n",
        "  train_extracted_del1.append(del_feat)\n",
        "  train_extracted_ddel1.append(ddel_feat) \n",
        "train_extracted1=np.array(train_extracted1)\n",
        "train_extracted_del1=np.array(train_extracted_del1)\n",
        "train_extracted_ddel1=np.array(train_extracted_ddel1)\n",
        "train_extracted_1=0\n",
        "train_extracted_1=np.hstack((train_extracted1,train_extracted_del1,train_extracted_ddel1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b398933",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_extracted2=[]\n",
        "train_extracted_del2=[]\n",
        "train_extracted_ddel2=[]\n",
        "# class normal\n",
        "files = os.listdir(path2)\n",
        "for i in files:\n",
        "  string = path2 + '/'+i\n",
        "  data,sr = librosa.load(string)\n",
        "  train_dataset.append(data)\n",
        "  train_labels.append('normal')  \n",
        "  feat,del_feat,ddel_feat=mfcc_mine(sr,data)  \n",
        "  train_extracted2.append(feat)\n",
        "  train_extracted_del2.append(del_feat)\n",
        "  train_extracted_ddel2.append(ddel_feat)  \n",
        "train_extracted2=np.array(train_extracted2)\n",
        "train_extracted_del2=np.array(train_extracted_del2)\n",
        "train_extracted_ddel2=np.array(train_extracted_ddel2)\n",
        "train_extracted_2=0\n",
        "train_extracted_2=np.hstack((train_extracted2,train_extracted_del2,train_extracted_ddel2))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a040091",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_extracted3=[]\n",
        "train_extracted_del3=[]\n",
        "train_extracted_ddel3=[]\n",
        "# class pain\n",
        "files = os.listdir(path3)\n",
        "for i in files:\n",
        "  string = path3 + '/'+i\n",
        "  data,sr = librosa.load(string)\n",
        "  train_dataset.append(data)\n",
        "  train_labels.append('normal')  \n",
        "  feat,del_feat,ddel_feat=mfcc_mine(sr,data)  \n",
        "  train_extracted3.append(feat)\n",
        "  train_extracted_del3.append(del_feat)\n",
        "  train_extracted_ddel3.append(ddel_feat)  \n",
        "train_extracted3=np.array(train_extracted3)\n",
        "train_extracted_del3=np.array(train_extracted_del3)\n",
        "train_extracted_ddel3=np.array(train_extracted_ddel3)\n",
        "train_extracted_3=0\n",
        "train_extracted_3=np.hstack((train_extracted3,train_extracted_del3,train_extracted_ddel3))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad16068",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_extracted5=[]\n",
        "train_extracted_del5=[]\n",
        "train_extracted_ddel5=[]\n",
        "# class pathology\n",
        "files = os.listdir(path5)\n",
        "for i in files:\n",
        "  string = path5 + '/'+i\n",
        "  data,sr = librosa.load(string)\n",
        "  train_dataset.append(data)\n",
        "  train_labels.append('pathology')  \n",
        "  feat,del_feat,ddel_feat=mfcc_mine(sr,data)  \n",
        "  train_extracted5.append(feat)\n",
        "  train_extracted_del5.append(del_feat)\n",
        "  train_extracted_ddel5.append(ddel_feat)  \n",
        "train_extracted5=np.array(train_extracted5)\n",
        "train_extracted_del5=np.array(train_extracted_del5)\n",
        "train_extracted_ddel5=np.array(train_extracted_ddel5)\n",
        "train_extracted_5=0\n",
        "train_extracted_5=np.hstack((train_extracted5,train_extracted_del5,train_extracted_ddel5))    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "178bfb4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_extracted6=[]\n",
        "train_extracted_del6=[]\n",
        "train_extracted_ddel6=[]\n",
        "# class pathology\n",
        "files = os.listdir(path6)\n",
        "for i in files:\n",
        "  string = path6 + '/'+i\n",
        "  data,sr = librosa.load(string)\n",
        "  train_dataset.append(data)\n",
        "  train_labels.append('normal')  \n",
        "  feat,del_feat,ddel_feat=mfcc_mine(sr,data)  \n",
        "  train_extracted6.append(feat)\n",
        "  train_extracted_del6.append(del_feat)\n",
        "  train_extracted_ddel6.append(ddel_feat)  \n",
        "train_extracted6=np.array(train_extracted6)\n",
        "train_extracted_del6=np.array(train_extracted_del6)\n",
        "train_extracted_ddel6=np.array(train_extracted_ddel6)\n",
        "train_extracted_6=0\n",
        "train_extracted_6=np.hstack((train_extracted6,train_extracted_del6,train_extracted_ddel6))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79a8528",
      "metadata": {},
      "outputs": [],
      "source": [
        "train_extracted_1=np.array(train_extracted_1)\n",
        "train_extracted_2=np.array(train_extracted_2)\n",
        "train_extracted_3=np.array(train_extracted_3)\n",
        "train_extracted_5=np.array(train_extracted_5)\n",
        "train_extracted_6=np.array(train_extracted_6)\n",
        "train_extracted=0\n",
        "train_extracted=np.vstack((train_extracted_1,train_extracted_2,train_extracted_3,train_extracted_5,train_extracted_6))\n",
        "print(train_extracted.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e7b41f",
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------------------------#labels encoder-------------------------------\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import preprocessing\n",
        "unique,counts=np.unique(train_labels,return_counts=True)\n",
        "print(np.asarray((unique,counts)))\n",
        "label_encoder=preprocessing.LabelEncoder()\n",
        "train_labels=label_encoder.fit_transform(train_labels)\n",
        "uniques=['normal','pathology']\n",
        "plt.bar(uniques,counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0633723c",
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------------------------#train test split------------------------------\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(train_extracted,train_labels,test_size=0.30,random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81a05a73",
      "metadata": {},
      "outputs": [],
      "source": [
        "#----------------------------------#training part---------------------------------------\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier=KNeighborsClassifier(n_neighbors=3)\n",
        "classifier.fit(x_train,y_train)\n",
        "knnPickle = open('knnpickle_file', 'wb')     \n",
        "# source, destination \n",
        "pickle.dump(classifier, knnPickle)  \n",
        "# close the file\n",
        "knnPickle.close()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "beedbe2faf2f7048d727558d0bc3221e7eba2a0b921cac4d4771b2feb8f74b30"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
